package provider

import (
	"context"
	"encoding/json"
	"fmt"
	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringdefault"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-log/tflog"
	"github.com/tatari-tv/terraform-provider-altinitycloud/cmd/client"
	"time"
)

// Ensure the implementation satisfies the expected interfaces.
var (
	_ resource.Resource                = &nodeTypeResource{}
	_ resource.ResourceWithConfigure   = &nodeTypeResource{}
	_ resource.ResourceWithImportState = &nodeTypeResource{}
)

// NewNodeTypeResource is a helper function to simplify the provider implementation.
func NewNodeTypeResource() resource.Resource {
	return &nodeTypeResource{}
}

// nodeTypeResource is the resource implementation.
type nodeTypeResource struct {
	client *client.AltinityCloudClient
}

// Configure adds the provider configured client to the resource.
func (r *nodeTypeResource) Configure(_ context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {
	if req.ProviderData == nil {
		return
	}

	client, ok := req.ProviderData.(*client.AltinityCloudClient)

	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected NodeTypes Source Configure Type",
			fmt.Sprintf("Expected *hashicups.Client, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)

		return
	}

	r.client = client
}

// Metadata - returns the resource type name.
func (r *nodeTypeResource) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_node_type"
}

// Schema - defines the schema for the resource.
func (r *nodeTypeResource) Schema(_ context.Context, _ resource.SchemaRequest, resp *resource.SchemaResponse) {
	resp.Schema = schema.Schema{
		Attributes: map[string]schema.Attribute{
			"env_id": schema.StringAttribute{
				Required:            true,
				MarkdownDescription: "Altinity.Cloud environment ID",
			},
			"node_type": schema.SingleNestedAttribute{
				Required: true,
				Attributes: map[string]schema.Attribute{
					"id": schema.StringAttribute{
						Computed:            true,
						MarkdownDescription: "Altinity.Cloud node type ID.",
					},
					"name": schema.StringAttribute{
						Required:            true,
						MarkdownDescription: "Altinity.Cloud node type name.",
					},
					"scope": schema.StringAttribute{
						Required:            true,
						MarkdownDescription: "Kubernetes node type scope (either `ClickHouse` or `Zookeeper`).",
					},
					"code": schema.StringAttribute{
						Required:            true,
						MarkdownDescription: "Name Identifier for the node type.",
					},
					"pool": schema.StringAttribute{
						Required:            true,
						MarkdownDescription: "Kubernetes provider label name.",
					},
					"storage_class": schema.StringAttribute{
						Required:            true,
						MarkdownDescription: "Kubernetes disk storage class type (either `gp2 or `gp3`).",
					},
					"memory": schema.StringAttribute{
						Required:            true,
						MarkdownDescription: "Kubernetes node memory size in MB.",
					},
					"cpu": schema.StringAttribute{
						Required:            true,
						MarkdownDescription: "Kubernetes node CPU size in cores.",
					},
					"extra_spec": schema.StringAttribute{
						Computed:            true,
						MarkdownDescription: "Extra specification for the node type in string JSON format as a string.",
						Default:             stringdefault.StaticString(""),
					},
					"node_selector": schema.StringAttribute{
						Computed:            true,
						MarkdownDescription: "Kubernetes node selector in string JSON format as a string.",
						Default:             stringdefault.StaticString(""),
					},
					"tolerations": schema.ListNestedAttribute{
						Optional:            true,
						MarkdownDescription: "Kubernetes node tolerations.",
						NestedObject: schema.NestedAttributeObject{
							Attributes: map[string]schema.Attribute{
								"key": schema.StringAttribute{
									Optional: true,
								},
								"operator": schema.StringAttribute{
									Optional: true,
								},
								"effect": schema.StringAttribute{
									Optional: true,
								},
								"value": schema.StringAttribute{
									Optional: true,
								},
							},
						},
					},
					"cpu_alloc": schema.StringAttribute{
						Computed:            true,
						MarkdownDescription: "Kubernetes node CPU allocation in cores. This is auto-generated by the provider.",
					},
					"memory_alloc": schema.StringAttribute{
						Computed:            true,
						MarkdownDescription: "Kubernetes node memory allocation in MB. This is auto-generated by the provider.",
					},
				},
			},
			"last_updated": schema.StringAttribute{
				Computed:            true,
				MarkdownDescription: "Altinity.Cloud node type last updated timestamp. This is auto-generated by the provider.",
			},
		},
	}
}

// Create - creates the resource and sets the initial Terraform state.
func (r *nodeTypeResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {
	tflog.Info(ctx, "Creating node type resource")
	// Retrieve values from plan
	var plan NodeTypeResourceModel
	diags := req.Plan.Get(ctx, &plan)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		tflog.Error(ctx, "Failed to retrieve plan for Altinity.Cloud node type resource")
		return
	}

	// Generate API request body from plan
	tflog.Info(ctx, "Generating API create request params from the plan")
	reqData := client.NodeType{
		ID:           plan.NodeType.ID.ValueString(),
		Name:         plan.NodeType.Name.ValueString(),
		Scope:        plan.NodeType.Scope.ValueString(),
		Code:         plan.NodeType.Code.ValueString(),
		Pool:         plan.NodeType.Pool.ValueString(),
		StorageClass: plan.NodeType.StorageClass.ValueString(),
		CPU:          plan.NodeType.CPU.ValueString(),
		Memory:       plan.NodeType.Memory.ValueString(),
		ExtraSpec:    plan.NodeType.ExtraSpec.ValueString(),
		NodeSelector: plan.NodeType.NodeSelector.ValueString(),
		Tolerations:  nil,
	}
	// Convert tolerations from schema to API format
	for _, nt := range plan.NodeType.Tolerations {
		reqData.Tolerations = append(reqData.Tolerations, client.Toleration{
			Key:      nt.Key.ValueString(),
			Operator: nt.Operator.ValueString(),
			Effect:   nt.Effect.ValueString(),
			Value:    nt.Value.ValueString(),
		})
	}

	// Create new Node Type
	data, err := json.Marshal(reqData)
	if err != nil {
		// This should never happen
		tflog.Info(ctx, "Failed to marshal node type request body")
	}
	// Create new Node Type
	tflog.Info(ctx, "Creating new node type via API "+string(data))
	nodeType, err := r.client.CreateNodeType(plan.EnvID.ValueString(), reqData)
	if err != nil {
		resp.Diagnostics.AddError(
			"Error creating node type",
			"Could not create node types, unexpected error: "+err.Error(),
		)
		return
	}

	// Map response body to schema and populate Computed attribute values
	d, _ := json.Marshal(nodeType)
	tflog.Info(ctx, fmt.Sprintf("Mapping response body to schema and populating Computed attribute values %s", string(d)))
	plan.NodeType = mapNodeTypeToNodeTypeResponse(nodeType)
	plan.LastUpdated = types.StringValue(time.Now().Format(time.RFC850))

	// Set plan to fully populated data
	diags = resp.State.Set(ctx, plan)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}
}

// Read refreshes the Terraform state with the latest data.
func (r *nodeTypeResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {
	tflog.Info(ctx, "Read Altinity.Cloud node type resource")
	// Get current plan
	var plan NodeTypeResourceModel
	diags := req.State.Get(ctx, &plan)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		tflog.Trace(ctx, fmt.Sprintf("failed to get terraform plan %v", resp.Diagnostics))
		return
	}

	// Get refreshed node types from Altinity.Cloud
	tflog.Trace(ctx, fmt.Sprintf("env id %v node type name %v", plan.EnvID.String(), plan.NodeType.Name.String()))
	nodeType, err := r.client.GetNodeType(plan.EnvID.ValueString(), plan.NodeType.Name.ValueString())
	tflog.Trace(ctx, fmt.Sprintf("got node type from API %v", nodeType))
	if err != nil {
		resp.Diagnostics.AddError(
			"Error retrieving node types",
			"Could not retrieve node types, unexpected error: "+err.Error(),
		)
		return
	}

	// Overwrite current plan with refreshed data
	updatedState := NodeTypeModel{
		ID:           types.StringValue(nodeType.ID),
		Scope:        types.StringValue(nodeType.Scope),
		Code:         types.StringValue(nodeType.Code),
		Name:         types.StringValue(nodeType.Name),
		Pool:         types.StringValue(nodeType.Pool),
		StorageClass: types.StringValue(nodeType.StorageClass),
		CPU:          types.StringValue(nodeType.CPU),
		Memory:       types.StringValue(nodeType.Memory),
		ExtraSpec:    types.StringValue(nodeType.ExtraSpec),
		NodeSelector: types.StringValue(nodeType.NodeSelector),
		CPUAlloc:     types.StringValue(nodeType.CPUAlloc),
		MemoryAlloc:  types.StringValue(nodeType.MemoryAlloc),
	}

	for _, t := range nodeType.Tolerations {
		updatedState.Tolerations = append(updatedState.Tolerations, TolerationModel{
			Key:      types.StringValue(t.Key),
			Operator: types.StringValue(t.Operator),
			Effect:   types.StringValue(t.Effect),
			Value:    types.StringValue(t.Value),
		})
	}
	// update plan with node type
	plan.NodeType = updatedState

	tflog.Trace(ctx, fmt.Sprintf("refreshed node types from API in environment %v", plan.EnvID))

	// set refreshed plan
	diags = resp.State.Set(ctx, plan)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}
}

// Update - updates the resource and sets the updated Terraform state on success.
func (r *nodeTypeResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {
	tflog.Info(ctx, "Update node type resource")
	// Retrieve values from plan
	var plan NodeTypeResourceModel
	diags := req.Plan.Get(ctx, &plan)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		tflog.Error(ctx, "Failed to retrieve plan for Altinity.Cloud node type resource")
		return
	}

	// Generate API request body from plan
	tflog.Info(ctx, "Generating API update request params from the plan")
	reqData := client.NodeType{
		Name:         plan.NodeType.Name.ValueString(),
		Scope:        plan.NodeType.Scope.ValueString(),
		Code:         plan.NodeType.Code.ValueString(),
		Pool:         plan.NodeType.Pool.ValueString(),
		StorageClass: plan.NodeType.StorageClass.ValueString(),
		CPU:          plan.NodeType.CPU.ValueString(),
		Memory:       plan.NodeType.Memory.ValueString(),
		ExtraSpec:    plan.NodeType.ExtraSpec.ValueString(),
		NodeSelector: plan.NodeType.NodeSelector.ValueString(),
		Tolerations:  nil,
	}
	// Convert tolerations from schema to API format
	for _, nt := range plan.NodeType.Tolerations {
		reqData.Tolerations = append(reqData.Tolerations, client.Toleration{
			Key:      nt.Key.ValueString(),
			Operator: nt.Operator.ValueString(),
			Effect:   nt.Effect.ValueString(),
			Value:    nt.Value.ValueString(),
		})
	}

	// Update node type in Altinity.Cloud
	tflog.Info(ctx, fmt.Sprintf("Updating node type %s in environment ID %s", plan.NodeType.Name.ValueString(), plan.EnvID.ValueString()))
	nodeType, err := r.client.UpdateNodeType(plan.EnvID.ValueString(), reqData)
	if err != nil {
		resp.Diagnostics.AddError(
			"Error updating node type",
			"Could not update node type, unexpected error: "+err.Error(),
		)
		return
	}

	// Map response body to schema and populate Computed attribute values
	d, _ := json.Marshal(nodeType)
	tflog.Info(ctx, fmt.Sprintf("Mapping response body to schema and populating Computed attribute values %s", string(d)))
	plan.NodeType = mapNodeTypeToNodeTypeResponse(nodeType)
	plan.LastUpdated = types.StringValue(time.Now().Format(time.RFC850))

	// Set plan to fully populated data
	diags = resp.State.Set(ctx, plan)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}
}

// Delete - deletes the resource and removes the Terraform state on success.
func (r *nodeTypeResource) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {
	tflog.Info(ctx, "Delete node type resource")
	// Retrieve values from plan
	var state NodeTypeResourceModel
	diags := req.State.Get(ctx, &state)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	// Delete existing order
	err := r.client.DeleteNodeType(state.NodeType.ID.ValueString())
	if err != nil {
		resp.Diagnostics.AddError(
			"Error Deleting HashiCups Order",
			"Could not delete order, unexpected error: "+err.Error(),
		)
		return
	}
}

func (r *nodeTypeResource) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {
	tflog.Info(ctx, "Import node type resource")
	// Retrieve import ID and save to id attribute
	resource.ImportStatePassthroughID(ctx, path.Root("id"), req, resp)
}

func mapNodeTypeToNodeTypeResponse(nodeType client.NodeType) NodeTypeModel {
	nodeTypeModel := NodeTypeModel{
		// require parameters
		ID:           types.StringValue(nodeType.ID),
		Name:         types.StringValue(nodeType.Name),
		Scope:        types.StringValue(nodeType.Scope),
		Code:         types.StringValue(nodeType.Code),
		Pool:         types.StringValue(nodeType.Pool),
		StorageClass: types.StringValue(nodeType.StorageClass),
		CPU:          types.StringValue(nodeType.CPU),
		Memory:       types.StringValue(nodeType.Memory),
		ExtraSpec:    types.StringValue(nodeType.ExtraSpec),
		NodeSelector: types.StringValue(nodeType.NodeSelector),
		CPUAlloc:     types.StringValue(nodeType.CPUAlloc),
		MemoryAlloc:  types.StringValue(nodeType.MemoryAlloc),
	}

	// set optional tolerations if they are not empty
	if len(nodeType.Tolerations) > 0 {
		for _, t := range nodeType.Tolerations {
			nodeTypeModel.Tolerations = append(nodeTypeModel.Tolerations, TolerationModel{
				Key:      types.StringValue(t.Key),
				Operator: types.StringValue(t.Operator),
				Effect:   types.StringValue(t.Effect),
				Value:    types.StringValue(t.Value),
			})
		}
	}
	return nodeTypeModel
}
