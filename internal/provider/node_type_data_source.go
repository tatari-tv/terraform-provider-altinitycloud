package provider

import (
	"context"
	"fmt"
	"github.com/hashicorp/terraform-plugin-framework/datasource"
	"github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-log/tflog"
	"github.com/tatari-tv/terraform-provider-altinitycloud/cmd/client"
)

// Ensure the implementation satisfies the expected interfaces.
var (
	_ datasource.DataSource              = &nodeTypeDataSource{}
	_ datasource.DataSourceWithConfigure = &nodeTypeDataSource{}
)

func NewNodeTypesDataSource() datasource.DataSource {
	return &nodeTypeDataSource{}
}

// nodeTypeDataSource - defines the Data source implementation.
type nodeTypeDataSource struct {
	client *client.AltinityCloudClient
}

// Metadata - returns the altinitycloud_node_type type name.
func (d *nodeTypeDataSource) Metadata(ctx context.Context, req datasource.MetadataRequest, resp *datasource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_node_type"
}

// Schema - defines the node_type schema.
func (d *nodeTypeDataSource) Schema(ctx context.Context, req datasource.SchemaRequest, resp *datasource.SchemaResponse) {
	resp.Schema = schema.Schema{
		Attributes: map[string]schema.Attribute{
			"env_id": schema.StringAttribute{
				MarkdownDescription: "Altinity.Cloud environment ID",
				Required:            true,
			},
			"name": schema.StringAttribute{
				Required:            true,
				MarkdownDescription: "Altinity.Cloud node type name.",
			},
			"id": schema.StringAttribute{
				Optional:            true,
				MarkdownDescription: "Altinity.Cloud node type ID.",
			},
			"scope": schema.StringAttribute{
				Optional:            true,
				MarkdownDescription: "Kubernetes node type scope (either `ClickHouse` or `Zookeeper`).",
			},
			"code": schema.StringAttribute{
				Optional:            true,
				MarkdownDescription: "Name Identifier for the node type.",
			},
			"pool": schema.StringAttribute{
				Optional:            true,
				MarkdownDescription: "Kubernetes provider label name.",
			},
			"storage_class": schema.StringAttribute{
				Optional:            true,
				MarkdownDescription: "Kubernetes disk storage class type (either `gp2 or `gp3`).",
			},
			"memory": schema.StringAttribute{
				Optional:            true,
				MarkdownDescription: "Kubernetes node memory size in MB.",
			},
			"cpu": schema.StringAttribute{
				Optional:            true,
				MarkdownDescription: "Kubernetes node CPU size in cores.",
			},
			"extra_spec": schema.StringAttribute{
				Optional:            true,
				MarkdownDescription: "Extra specification for the node type in string JSON format as a string.",
			},
			"node_selector": schema.StringAttribute{
				Optional:            true,
				MarkdownDescription: "Kubernetes node selector in string JSON format as a string.",
			},
			"tolerations": schema.ListNestedAttribute{
				Optional:            true,
				MarkdownDescription: "Kubernetes node tolerations.",
				NestedObject: schema.NestedAttributeObject{
					Attributes: map[string]schema.Attribute{
						"key": schema.StringAttribute{
							Optional: true,
						},
						"operator": schema.StringAttribute{
							Optional: true,
						},
						"effect": schema.StringAttribute{
							Optional: true,
						},
						"value": schema.StringAttribute{
							Optional: true,
						},
					},
				},
			},
			"cpu_alloc": schema.StringAttribute{
				Computed:            true,
				MarkdownDescription: "Kubernetes node CPU allocation in cores. This is auto-generated by the provider.",
			},
			"memory_alloc": schema.StringAttribute{
				Computed:            true,
				MarkdownDescription: "Kubernetes node memory allocation in MB. This is auto-generated by the provider.",
			},
		},
	}
}

// Configure - bootstraps node type datasource with Altinity.Cloud client.
func (d *nodeTypeDataSource) Configure(ctx context.Context, req datasource.ConfigureRequest, resp *datasource.ConfigureResponse) {
	tflog.Info(ctx, "Configuring node type data source")
	// Prevent panic if the provider has not been configured.
	if req.ProviderData == nil {
		return
	}

	client, ok := req.ProviderData.(*client.AltinityCloudClient)

	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected Data Source Configure Type",
			fmt.Sprintf("Expected *altinityCloudClient, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)

		return
	}

	d.client = client
}

// Read - implements the read functionality for node type.
func (d *nodeTypeDataSource) Read(ctx context.Context, req datasource.ReadRequest, resp *datasource.ReadResponse) {
	tflog.Info(ctx, "Reading node type state source")
	var state NodeTypeDataSourceModel
	diags := req.Config.Get(ctx, &state)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	// initialize provider client state and make a call using it.
	nodeType, err := d.client.GetNodeType(state.EnvID.ValueString(), state.Name.ValueString())
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to read example, got error: %s", err))
		return
	}

	// Create a new state object using the response.
	updateNodeType := NodeTypeModel{
		ID:           types.StringValue(nodeType.ID),
		Scope:        types.StringValue(nodeType.Scope),
		Code:         types.StringValue(nodeType.Code),
		Name:         types.StringValue(nodeType.Name),
		Pool:         types.StringValue(nodeType.Pool),
		StorageClass: types.StringValue(nodeType.StorageClass),
		CPU:          types.StringValue(nodeType.CPU),
		Memory:       types.StringValue(nodeType.Memory),
		ExtraSpec:    types.StringValue(nodeType.ExtraSpec),
		NodeSelector: types.StringValue(nodeType.NodeSelector),
		CPUAlloc:     types.StringValue(nodeType.CPUAlloc),
		MemoryAlloc:  types.StringValue(nodeType.MemoryAlloc),
	}
	for _, t := range nodeType.Tolerations {
		updateNodeType.Tolerations = append(updateNodeType.Tolerations, TolerationModel{
			Key:      types.StringValue(t.Key),
			Operator: types.StringValue(t.Operator),
			Effect:   types.StringValue(t.Effect),
			Value:    types.StringValue(t.Value),
		})
	}

	state.ID = updateNodeType.ID
	state.Name = updateNodeType.Name
	state.Scope = updateNodeType.Scope
	state.Code = updateNodeType.Code
	state.Pool = updateNodeType.Pool
	state.StorageClass = updateNodeType.StorageClass
	state.CPU = updateNodeType.CPU
	state.Memory = updateNodeType.Memory
	state.ExtraSpec = updateNodeType.ExtraSpec
	state.NodeSelector = updateNodeType.NodeSelector
	state.CPUAlloc = updateNodeType.CPUAlloc
	state.MemoryAlloc = updateNodeType.MemoryAlloc
	state.Tolerations = updateNodeType.Tolerations

	tflog.Trace(ctx, fmt.Sprintf("fetch node types from Altinity.Cloud API in environment %v", state.EnvID))

	// Set state
	diags = resp.State.Set(ctx, &state)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}
}
